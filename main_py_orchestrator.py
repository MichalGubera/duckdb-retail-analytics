#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DuckDB Retail Analytics - GÅ‚Ã³wny plik orchestrator
==================================================

Ten plik koordynuje caÅ‚y workflow projektu:
1. Generacja danych
2. Analiza z DuckDB  
3. Tworzenie raportÃ³w
4. Eksport wynikÃ³w

Autor: [Twoje ImiÄ™]
Data: 2025-09-07
"""

import os
import sys
from pathlib import Path
import argparse
import logging
from datetime import datetime

# Dodaj Å›cieÅ¼ki do moduÅ‚Ã³w projektu
project_root = Path(__file__).parent
sys.path.append(str(project_root / "src"))

# Import moduÅ‚Ã³w projektu
try:
    from src.data_generation.retail_data_generator import generate_retail_sales_data
    from src.analysis.duckdb_analyzer import DuckDBAnalyzer
    from src.utils.logger_config import setup_logging
    from src.utils.config_manager import ConfigManager
except ImportError as e:
    print(f"âŒ BÅ‚Ä…d importu moduÅ‚Ã³w: {e}")
    print("ğŸ’¡ Upewnij siÄ™, Å¼e wszystkie wymagane pliki sÄ… w odpowiednich katalogach")
    sys.exit(1)

class ProjectOrchestrator:
    """
    GÅ‚Ã³wna klasa koordynujÄ…ca caÅ‚y projekt
    """
    
    def __init__(self, config_path=None):
        """
        Inicjalizacja orchestratora
        
        Args:
            config_path (str): ÅšcieÅ¼ka do pliku konfiguracyjnego
        """
        self.project_root = Path(__file__).parent
        self.config = ConfigManager(config_path)
        self.logger = setup_logging()
        self.analyzer = None
        
        # UtwÃ³rz katalogi jeÅ›li nie istniejÄ…
        self.ensure_directories()
        
    def ensure_directories(self):
        """Upewnij siÄ™, Å¼e wszystkie wymagane katalogi istniejÄ…"""
        dirs_to_create = [
            self.config.raw_data_dir,
            self.config.processed_data_dir,
            self.config.output_dir,
            self.config.figures_dir,
            self.config.reports_dir
        ]
        
        for directory in dirs_to_create:
            directory.mkdir(parents=True, exist_ok=True)
            
    def step_1_generate_data(self, num_records=None, force_regenerate=False):
        """
        Krok 1: Generacja danych sprzedaÅ¼y
        
        Args:
            num_records (int): Liczba rekordÃ³w do wygenerowania
            force_regenerate (bool): Czy wymuszaÄ‡ regeneracjÄ™ danych
        """
        self.logger.info("ğŸ”„ KROK 1: Generacja danych sprzedaÅ¼y")
        
        csv_file = self.config.raw_data_dir / "retail_sales_data.csv"
        
        # SprawdÅº czy dane juÅ¼ istniejÄ…
        if csv_file.exists() and not force_regenerate:
            self.logger.info(f"ğŸ“„ Dane juÅ¼ istniejÄ… w: {csv_file}")
            self.logger.info("ğŸ’¡ UÅ¼yj --regenerate Å¼eby wygenerowaÄ‡ nowe dane")
            return str(csv_file)
        
        try:
            num_records = num_records or self.config.default_num_records
            self.logger.info(f"ğŸ“Š GenerujÄ™ {num_records:,} rekordÃ³w danych...")
            
            # Generuj dane
            retail_data = generate_retail_sales_data(num_records)
            
            # Zapisz do CSV
            import pandas as pd
            df = pd.DataFrame(retail_data)
            df.to_csv(csv_file, index=False, encoding='utf-8')
            
            # Statystyki
            self.logger.info(f"âœ… Wygenerowano {len(df):,} rekordÃ³w")
            self.logger.info(f"ğŸ“ Zapisano do: {csv_file}")
            self.logger.info(f"ğŸ’° ÅÄ…czna wartoÅ›Ä‡ sprzedaÅ¼y: ${df['total_sale'].sum():,.2f}")
            
            return str(csv_file)
            
        except Exception as e:
            self.logger.error(f"âŒ BÅ‚Ä…d podczas generacji danych: {e}")
            raise
    
    def step_2_analyze_data(self, csv_file):
        """
        Krok 2: Analiza danych z DuckDB
        
        Args:
            csv_file (str): ÅšcieÅ¼ka do pliku CSV z danymi
        """
        self.logger.info("ğŸ”„ KROK 2: Analiza danych z DuckDB")
        
        try:
            # Inicjalizuj analyzer DuckDB
            self.analyzer = DuckDBAnalyzer(
                database_path=self.config.duckdb_file,
                logger=self.logger
            )
            
            # ZaÅ‚aduj dane do DuckDB
            self.analyzer.load_csv_data(csv_file, table_name="retail_sales")
            
            # Wykonaj podstawowe analizy
            results = {}
            
            # 1. PrzeglÄ…d danych
            results['overview'] = self.analyzer.get_data_overview()
            
            # 2. Analiza sprzedaÅ¼y w czasie
            results['time_analysis'] = self.analyzer.analyze_sales_trends()
            
            # 3. Analiza kategorii produktÃ³w
            results['category_analysis'] = self.analyzer.analyze_product_categories()
            
            # 4. Segmentacja klientÃ³w
            results['customer_analysis'] = self.analyzer.analyze_customer_segments()
            
            # 5. Analiza rentownoÅ›ci
            results['profitability'] = self.analyzer.analyze_profitability()
            
            self.logger.info("âœ… Analiza danych zakoÅ„czona pomyÅ›lnie")
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ BÅ‚Ä…d podczas analizy danych: {e}")
            raise
    
    def step_3_generate_reports(self, analysis_results):
        """
        Krok 3: Generacja raportÃ³w i wizualizacji
        
        Args:
            analysis_results (dict): Wyniki analiz
        """
        self.logger.info("ğŸ”„ KROK 3: Generacja raportÃ³w")
        
        try:
            # Generuj raporty
            reports_generated = []
            
            # 1. Raport tekstowy
            text_report = self.analyzer.generate_text_report(analysis_results)
            report_file = self.config.reports_dir / f"retail_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
            
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(text_report)
            reports_generated.append(report_file)
            
            # 2. Wizualizacje
            charts_created = self.analyzer.create_visualizations(
                analysis_results, 
                output_dir=self.config.figures_dir
            )
            reports_generated.extend(charts_created)
            
            self.logger.info(f"âœ… Wygenerowano {len(reports_generated)} plikÃ³w:")
            for report in reports_generated:
                self.logger.info(f"   ğŸ“„ {report}")
            
            return reports_generated
            
        except Exception as e:
            self.logger.error(f"âŒ BÅ‚Ä…d podczas generacji raportÃ³w: {e}")
            raise
    
    def run_full_pipeline(self, num_records=None, force_regenerate=False):
        """
        Uruchom caÅ‚y pipeline projektu
        
        Args:
            num_records (int): Liczba rekordÃ³w do wygenerowania
            force_regenerate (bool): Czy wymuszaÄ‡ regeneracjÄ™ danych
        """
        start_time = datetime.now()
        self.logger.info("ğŸš€ ROZPOCZYNAM PEÅNY PIPELINE PROJEKTU")
        self.logger.info("="*60)
        
        try:
            # Krok 1: Generacja danych
            csv_file = self.step_1_generate_data(num_records, force_regenerate)
            
            # Krok 2: Analiza z DuckDB
            analysis_results = self.step_2_analyze_data(csv_file)
            
            # Krok 3: Raporty i wizualizacje
            reports = self.step_3_generate_reports(analysis_results)
            
            # Podsumowanie
            end_time = datetime.now()
            duration = end_time - start_time
            
            self.logger.info("="*60)
            self.logger.info("ğŸ‰ PIPELINE ZAKOÅƒCZONY POMYÅšLNIE!")
            self.logger.info(f"â±ï¸  Czas wykonania: {duration}")
            self.logger.info(f"ğŸ“Š Plik danych: {csv_file}")
            self.logger.info(f"ğŸ—ƒï¸  Baza DuckDB: {self.config.duckdb_file}")
            self.logger.info(f"ğŸ“ˆ Raporty: {len(reports)} plikÃ³w w {self.config.reports_dir}")
            self.logger.info("="*60)
            
        except Exception as e:
            self.logger.error(f"ğŸ’¥ PIPELINE PRZERWANY: {e}")
            raise
        finally:
            # Zamknij poÅ‚Ä…czenie z DuckDB
            if self.analyzer:
                self.analyzer.close()

def main():
    """GÅ‚Ã³wna funkcja uruchamiajÄ…ca"""
    
    # Argumenty linii poleceÅ„
    parser = argparse.ArgumentParser(
        description="DuckDB Retail Analytics - System analizy danych sprzedaÅ¼y",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
PrzykÅ‚ady uÅ¼ycia:
  python main.py                          # Uruchom peÅ‚ny pipeline
  python main.py --records 50000          # Wygeneruj 50k rekordÃ³w
  python main.py --regenerate             # Wymuszaj regeneracjÄ™ danych
  python main.py --step generate          # Tylko generacja danych
  python main.py --step analyze           # Tylko analiza danych
        """
    )
    
    parser.add_argument(
        '--records', '-r',
        type=int,
        default=10000,
        help='Liczba rekordÃ³w do wygenerowania (default: 10000)'
    )
    
    parser.add_argument(
        '--regenerate',
        action='store_true',
        help='Wymuszaj regeneracjÄ™ danych nawet jeÅ›li juÅ¼ istniejÄ…'
    )
    
    parser.add_argument(
        '--step', '-s',
        choices=['generate', 'analyze', 'reports', 'full'],
        default='full',
        help='KtÃ³ry krok uruchomiÄ‡ (default: full - wszystkie kroki)'
    )
    
    parser.add_argument(
        '--config', '-c',
        type=str,
        help='ÅšcieÅ¼ka do pliku konfiguracyjnego'
    )
    
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='SzczegÃ³Å‚owe informacje debug'
    )
    
    args = parser.parse_args()
    
    try:
        # Inicjalizuj orchestrator
        orchestrator = ProjectOrchestrator(config_path=args.config)
        
        if args.verbose:
            orchestrator.logger.setLevel(logging.DEBUG)
        
        # Wykonaj odpowiedni krok
        if args.step == 'generate':
            orchestrator.step_1_generate_data(args.records, args.regenerate)
        elif args.step == 'analyze':
            csv_file = orchestrator.config.raw_data_dir / "retail_sales_data.csv"
            if not csv_file.exists():
                print("âŒ Brak danych! Uruchom najpierw: python main.py --step generate")
                sys.exit(1)
            orchestrator.step_2_analyze_data(str(csv_file))
        elif args.step == 'reports':
            print("ğŸ”„ Funkcja raportÃ³w bÄ™dzie dostÄ™pna po implementacji analizy")
        else:  # full
            orchestrator.run_full_pipeline(args.records, args.regenerate)
            
    except KeyboardInterrupt:
        print("\nâš ï¸  Pipeline przerwany przez uÅ¼ytkownika")
        sys.exit(1)
    except Exception as e:
        print(f"ğŸ’¥ BÅ‚Ä…d: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()